{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aca1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23a2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def build_bag_of_words(document):\n",
    "    #온점 제거 및 형태소 분석\n",
    "    document = document.replace('.','')\n",
    "    tokenized_document = okt.morphs(document) #형태소 토큰화\n",
    "    \n",
    "    word_to_index={} #단어 사전\n",
    "    bow = []  #단어 가방\n",
    "    \n",
    "    #단어의 중복을 제거\n",
    "    for word in tokenized_document: #형태소 토큰화된 단어가\n",
    "        if word not in word_to_index.keys(): #단어 집합에 포함되지 않는다면\n",
    "            word_to_index[word] = len(word_to_index) #0이상의 정수를 차근차근 넣어준다.\n",
    "            #Bow에 전부 기본값1을 넣는다.\n",
    "            bow.insert(len(word_to_index)-1, 1)\n",
    "            #Bow는 빈도수 기반이니 단어가 가지는 인덱스 위치에 빈도수를 넣는다.\n",
    "        else:\n",
    "            #재등장하는 단어의 인덱스\n",
    "            index = word_to_index.get(word)#단어의 인덱스를 얻는다. 벡터의 위치\n",
    "            #재등장하는 단어는 해당하는 인덱스의 위치에 1을 더한다.\n",
    "            bow[index] = bow[index]+1\n",
    "    return word_to_index, bow #단어사전과 문장이 bow로 인코딩된 벡터\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb40099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어집합(단어:인덱스위치) :  {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
      "bag of words vector :  [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "vocab, bow = build_bag_of_words(text)\n",
    "print('단어집합(단어:인덱스위치) : ', vocab)\n",
    "print('bag of words vector : ', bow)\n",
    "#한 문장으로 동작해서 단어의 순서가 문장의 순서랑 같지 원래는 단어의 순서 무시하고 빈도수 기반 단어표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c409b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a16c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary : {'소비자': 0, '는': 1, '주로': 2, '소비': 3, '하는': 4, '상품': 5, '을': 6, '기준': 7, '으로': 8, '물가상승률': 9, '느낀다': 10}\n",
      "bag of words vector : [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab, bow = build_bag_of_words(doc2)\n",
    "print('vocabulary :', vocab)\n",
    "print('bag of words vector :', bow)  #문서를 수치화. 해당되는 단어의 인덱스에 벡터를 넣는다.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b6e949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab :  {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9, '는': 10, '주로': 11, '소비': 12, '상품': 13, '을': 14, '기준': 15, '으로': 16, '느낀다': 17}\n",
      "bag of words vector :  [1, 2, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#두개의 문장을 합쳐서\n",
    "#단어사전을 만들 수도 있고,\n",
    "#bow벡터 생성도 할수있다\n",
    "str = text+' '+doc2\n",
    "vocab, bow = build_bag_of_words(str)\n",
    "print('vocab : ', vocab)\n",
    "print('bag of words vector : ', bow)\n",
    "\n",
    "#단어들의 순서는 문시. 단어들의 인덱스에 초첨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8410a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 0.],\n",
       "       [0., 3., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=False)\n",
    "D = [{'A': 1, 'B': 2}, {'B': 3, 'C': 1}]\n",
    "#문서자체가 딕셔너리로 단어:빈도수로 되어 있어야 한다.\n",
    "X = v.fit_transform(D) #문서들을 bow벡터화\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b648f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc20dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0692aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 4.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform({'C':4, 'D':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98950a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 2 1 2 1]]\n",
      "vocabulary:  {'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus=['you know I want your love. because I love you'] #하나의 문서\n",
    "vector = CountVectorizer()\n",
    "\n",
    "#코퍼스로부터 각 단어의 빈도수를 기록\n",
    "print('bag of words vector :', vector.fit_transform(corpus).toarray())\n",
    "\n",
    "#각 단어의 인덱스가 어떻게 부여되었는지를 출력\n",
    "print('vocabulary: ', vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a1d0768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3 = ['I was so upset. because she bordered me']\n",
    "vector.transform(doc3).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5cc98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "    'The last document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28c4ab31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 9,\n",
       " 'is': 3,\n",
       " 'the': 7,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 6,\n",
       " 'and': 0,\n",
       " 'third': 8,\n",
       " 'one': 5,\n",
       " 'last': 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=\"word\").fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "989af72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cc9f554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(ngram_range=(2, 2))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eef04c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this is': 12,\n",
       " 'is the': 2,\n",
       " 'the first': 7,\n",
       " 'first document': 1,\n",
       " 'the second': 9,\n",
       " 'second second': 6,\n",
       " 'second document': 5,\n",
       " 'and the': 0,\n",
       " 'the third': 10,\n",
       " 'third one': 11,\n",
       " 'is this': 3,\n",
       " 'this the': 13,\n",
       " 'the last': 8,\n",
       " 'last document': 4}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e97a6d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform([\"is the book broken?\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd6de7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "    'The last document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98a009c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'this': 3, 'is': 2, 'first': 1, 'document': 0},\n",
       " {'and', 'last', 'one', 'second', 'the', 'third'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(max_df=4, min_df=2).fit(corpus)\n",
    "#문서에서 각 텍스트의 동일한 단어는 하나의 단어 취급 \n",
    "vect.vocabulary_, vect.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fb1e6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(corpus).toarray().sum(axis=0) #열방향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a1399b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42c7bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63692c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array shape :  (2, 2, 3)\n",
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(2*2*3).reshape(2,2,3)\n",
    "print('array shape : ', array.shape)\n",
    "print(array)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdd973a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b4b0b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  8, 10],\n",
       "       [12, 14, 16]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = np.sum(array,axis=0)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5b0b499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 12],\n",
       "       [21, 30]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = np.sum(array,axis=2) #축이 높다 1차원웍\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4942fe08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  5,  7],\n",
       "       [15, 17, 19]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = np.sum(array,axis=1)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e59de357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = np.arange(20).reshape(5,4)\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc4ed46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 45, 50, 55])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(array1,axis=0) #축이 낮다, 고차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81f62e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982b241",
   "metadata": {},
   "source": [
    "# (2)CountVectorizer에서 제공하는 자체 불용어 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c23baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1]]\n",
      "vocabulary : {'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "text = [\"Family is not an important thing. It's everything.\"] #문사\n",
    "vect = CountVectorizer(stop_words='english') #벡터화 클래스에 불용어 리스트 지정\n",
    "print('bag of words vector :',vect.fit_transform(text).toarray()) #텍스트를 학습과 벡터화\n",
    "print('vocabulary :',vect.vocabulary_) #단어 집합 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b45517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1 1]]\n",
      "vocabulary : {'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "# (3) nltk에서 제공하는 자체 불용어 사용\n",
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "stop_words = stopwords.words(\"english\")\n",
    "vect = CountVectorizer(stop_words=stop_words)\n",
    "print('bag of words vector :',vect.fit_transform(text).toarray()) \n",
    "print('vocabulary :',vect.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610b80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
